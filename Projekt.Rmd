---
title: "Projekt 1.0"
author: "Michał Baran"
date: "25 kwietnia 2019"
output: html_document
runtime: shiny
---
```{r, message=FALSE, results='hide', echo=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(tseries)
library(shiny)
```
### Wprowadzenie i hipotezy
Tematem projektu jest zbanianie mocy testów normalnościowych razkładu w przypadku gdy dane pochodzą z rozkładu _t-Studenta_. Moce testów zostaną zbadane w zależności od:  
* Długości próby.  
* Ilości stopni swodoby w rozkładzie t-Studenta.  
* Poziomu istotności.  

***
Do wykonania projektu posłużę się trzema testami normalności rozkładu:

- __Jarque Bera__  
Test ten jest najczęściej uzywanym testem w ekonometrii.Powodem tego jest jego prostota oraz znana nieskomplikowana postać rozkładu asymptotycznego. Konstrukcja statystyki testowej bazuje na wartościach momentów rozkłądu zmiennej losowej obliczonych na podstawie próby empiryczniej i porównaniu ich z momentami teoretycznumi rozkładu normalnego. Test weryfikuje hipotezę o jednowymiarowej normalności zmiennej losowej przeciwko innemu dowolnemu rozkładowi.

- __Shapiro-Wilka__  
Test ten jest uznawany za najlepszy do sprawdzania normalności rozkładu zmiennej losowej, ponieważ charakteryzuje go duża moc, czyli duże prawdopodobieństwo odrzucenia hipotezy zerowej jeśli jest ona fałszywa. Polecany jest dla małych próbek, ponieważ gdy liczba obserwacji przekracza 2000 może zwracać blędne wyniki. Test weryfikuje hipotezę mówiącą o o tym, że rozkład naszej zmiennej jest zbliżony do normalnego.

- __Kołmogorowa-Smirnowa__  
Test ten dla jednej próby służy testowaniu podobieństwa uzyskanego rozkładu naszej badanej zmiennej z innym teoretycznym rozkładem np.: normalnym, Poissona, czy jednostajnym. Najczęściej jednak w praktyce badań ilościowych test ten służy do oszacowania czy rozkład badanej zmiennej jest zbliżony do normalnego. Test weryfikuje hipotezę  o tym, że rozkład naszej zmiennej jest zbliżony do normalnego. 

***
Dane którymi będę się posługiwał przedstawię w postaci trzech wektorów.  

1. *alpha* - poziomy istotności 
2. *len* - długości próby  
3. *df* - stopnie swobody  

***
Obliczenia wykonane w projekcie będą miały na celu zbadanie prawdziwości poniższych hipotez:  

__Zależność od długości próby__  
H0: Zwiększnie długości próby powoduje wzrost mocy tesu   
H1: Zwiększnie długości próby powoduje spadek mocy tesu  

__Zależność od poziomu istotności__  
H0: Zwiększnie poziomu istotności powoduje wzrost mocy tesu  
H1: Zwiększnie poziomu istotności powoduje spadek mocy tesu  

__Zależność od ilości stopni swobody__  
H0: Zwiększnie ilości stopni swobody powoduje spadek mocy tesu  
H1: Zwiększnie ilości stopni swobody powoduje wzrost mocy tesu  

Oczekiwanym rezultatem w każdym przypadku jest brak postaw do odrzucenia hipotezy zerowej.

***
### Wizualizacja
Tworzę wektory danych, dzięki którym będę mógł przetestować postawione hipotezy:
```{r}
#ilosc symulacji
N <- 200
#poziom istotnosci
alpha <- c( .01, .05, .1, 0.15)
#stopnie swobody
df <- c(1:15)
#długość próby
len <- seq(14,30, by=2)  
```

Nastepnie tworzę ramkę danych, dzięki której będę sprawdzał poszczególne przypadki:
```{r}
data1 <- expand.grid(alpha,df,len)
colnames(data1) <- c("Poziom", "Stopnie", "Dlugosc")
```

Dla każdego testu przeprowadzam *N* symulacji, a nastepnie uśredniony wynik dla każdego przypadku zapisuję (przykład dla testu Jarque-Bera):
```{r}
set.seed(22)
powers_JB <- sapply(1:nrow(data1),function(i){
    df <- data1[i,2]
    n <-  data1[i,3]
    alpha <- data1[i,1]
    
    p_vector <- sapply(rep(df,N), function(j){
      JR_sample <- rt(n,df)
      jarque.bera.test(JR_sample)$p.value
    })
    mean(p_vector < alpha)
})
dataa_JB <- bind_cols(data1, Moc = powers_JB)
```

To samo powtarzam dla testu Shapiro-Wilka oraz Kołmogorowa-Smirnowa.
```{r, message=FALSE, results='hide', echo=FALSE, warning=FALSE}
#SW
set.seed(22)

powers_SW <- sapply(1:nrow(data1),function(i){
    df <- data1[i,2]
    n <-  data1[i,3]
    alpha <- data1[i,1]
    
    p_vector <- sapply(rep(df,N), function(j){
      SW_sample <- rt(n,df)
      shapiro.test(SW_sample)$p.value
    })
    mean(p_vector < alpha)
})

dataa_SW <- bind_cols(data1, Moc = powers_SW)
```

```{r, message=FALSE, results='hide', echo=FALSE, warning=FALSE}
#KS
set.seed(22)

powers_KS <- sapply(1:nrow(data1),function(i){
    df <- data1[i,2]
    n <-  data1[i,3]
    alpha <- data1[i,1]
    
    p_vector <- sapply(rep(df,N), function(j){
      KS_sample <- rt(n,df)
      ks.test(KS_sample, pnorm)$p.value
    })
    mean(p_vector < alpha)
})

dataa_KS <- bind_cols(data1, Moc = powers_KS)

```

Do pierwotnej ramki danych dodaję kolumny z mocami poszczególnych testów:
```{r}
dataa <- bind_cols(data1, MocJB = powers_JB, MocKS = powers_KS, MocSW = powers_SW)
```

Tworzę aplikację shiny, który pozwoli na łatwe i przejrzyste zaobserwowanie badanych przez nas aspektów:
```{r, echo=FALSE}
ui <- fluidPage(
  titlePanel("Wykresy!"),
  navbarPage("MENU",
    tabPanel("Testy",
      sidebarLayout(
        sidebarPanel(
          selectInput("test", "Wybierz test:", choices = c("JB","SW", "KS")),
          sliderInput("length1", "Wybierz dlugosc proby:", min = 14, max = 30, value = c(14:30), step = 2)
        ),
        mainPanel(
          plotOutput("plot1")
          )
          )),
  
    tabPanel("Zestawienie",
            sidebarLayout(
              sidebarPanel(
              selectInput("length2", "Wybierz dlugosc proby:", choices = seq(14,30, by=2)),
              selectInput("level", "wybierz poziom istotnosci:", choices = c( .01, .05, .1, .15) )
              ),
            mainPanel(
              plotOutput("plot2")
            )
            ))

))

  
server <- function(input, output, session) {
  
  now <- reactive({
    if(input$test == "SW"){
      index <- which(dataa_SW$Dlugosc >= input$length1[1] & dataa_SW$Dlugosc <= input$length1[2])
      now <- dataa_SW[index,]
    }
    else if (input$test == "JB"){
      index <- which(dataa_SW$Dlugosc >= input$length1[1] & dataa_SW$Dlugosc <= input$length1[2])
      now <- dataa_JB[index,]
    }
    else if (input$test == "KS"){
      index <- which(dataa_SW$Dlugosc >= input$length1[1] & dataa_SW$Dlugosc <= input$length1[2])
      now <- dataa_KS[index,]
    }
  })
  
  now2 <- reactive({
    lol <- filter(dataa, dataa$Poziom == input$level & dataa$Dlugosc == input$length2)
    
    
      lol$newcolumn <- sapply(1:nrow(lol),function(i){
      mean(lol[i,4],lol[i,5],lol[i,6])
    })
      colnames(lol)[7] <- "Moc"
      now2 <- lol
  })
  
  output$plot1 <- renderPlot({
    plot <- ggplot(now())+
    geom_smooth(aes(x = Stopnie, y = Moc, color = "red"))+
    facet_wrap(~ Poziom, ncol =  2)
    plot + theme(legend.position = "none") 
  })

  output$plot2 <- renderPlot({
      plot <- ggplot(now2() ,aes(x = Stopnie, y = Moc))+
      geom_line(aes(x = Stopnie, y = MocJB, color = "JB"))+
      geom_line(aes(x = Stopnie, y = MocSW, color = "SW"))+
      geom_line(aes(x = Stopnie, y = MocKS, color = "KS"))+
      labs(title = "Zestawienie testow")
      plot + labs(color = "Testy")
  })
} 

shinyApp(ui = ui, server = server, options = list(height = 540))
```

***
### Interpretacja  

Hipotezy początkowe:  

__Zależność od długości próby__  
H0: Zwiększnie długości próby powoduje wzrost mocy tesu   
H1: Zwiększnie długości próby powoduje spadek mocy tesu  

__Zależność od poziomu istotności__  
H0: Zwiększnie poziomu istotności powoduje wzrost mocy tesu  
H1: Zwiększnie poziomu istotności powoduje spadek mocy tesu  

__Zależność od ilości stopni swobody__  
H0: Zwiększnie ilości stopni swobody powoduje spadek mocy tesu  
H1: Zwiększnie ilości stopni swobody powoduje wzrost mocy tesu  

***

Po wynonaniu powyższej analizy można można stwierdzieć, że w każdym z trzech przypadków nie ma podstaw do odrzucnia hipotezy zerowej.  

Oznacza to, że zwiększenie długości próby, tak samo jak poziomu istotności powoduje wzrost mocy badanego testu. Jednak zwiększenie ilości stopni swobody jego zmniejsznie.  

Najsłabszym testem okazał się test Kołmogorowa-Smirnowa, a najmocniejszym Shapiro-Wilka. (Należy jednak pamiętać, że długość naszej próbki jest niewielka, a dla takich właśnie test Shapiro-Wilka sprawdza się najlepiej)  

***
Uprostrzenia, które mogą mieć wpływ na wyniki przeprowadzonej analizy:  
- uprostrzone wizualizacja mocy testów normalnościowych  
- dość mała długość próby  
- mała liczba symulacji każdego testu  

***

